{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neccessory Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation Parameters\n",
    "T = 100  # Time span for one slot 100ms\n",
    "mu = 0.02   # Sensing duration ratio \n",
    "t = mu*T    # Sensing time\n",
    "# PU = 1       # No. of PU\n",
    "N = 3       # No. of SU\n",
    "Pr = 0.5    # Probability of spectrum occupancy\n",
    "Pd = 0.9    # Probability of detection\n",
    "Pf = 0.1    # Probability of false alarm\n",
    "m = np.full(N,20)      # Battery capacity\n",
    "Eh = 0.1    # Harvested energy during one slot \n",
    "Pw = -60    # Primary signal power in dBm\n",
    "PowerTx = 10**(Pw/10)*1e-3  # Transmitted power\n",
    "Nw = -70    # Noise power in dBm\n",
    "PowerNo = 10**(Nw/10)*1e-3\n",
    "g = 10**-5  # Path loss coefficeint 10^(-5)\n",
    "w = 5e6     # Bandwidth\n",
    "samples = 50 # No. of sample\n",
    "# N = SU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======== Monte Carlo Simulation ========================\n",
    "def MCS(t,realiz,kind='ray',variance=2,N=3):\n",
    "    PU = np.array([0,0])*1e3                                # PU position \t\n",
    "    SU = np.array([[0,5],[0,7.5],[0,1]])*1e3               # SU position\n",
    "                    \n",
    "                               \n",
    "    # samples=round(2*T*w)                                    # No. of samples\n",
    "    \n",
    "    # N = SU\n",
    "    # PU-SU distance\n",
    "    d = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        d[i] = np.linalg.norm(PU-SU[i,:])\n",
    "\n",
    "    \n",
    "        \n",
    "    Y = np.zeros((realiz,N))                 \n",
    "    S = np.zeros(realiz)                   \n",
    "    SNR = np.zeros((N,realiz))            \n",
    "        \n",
    "    for k in range(realiz):\n",
    "        n = gaussianNoise(PowerNo,samples)\n",
    "        H = channel(N,d,g,kind,variance,samples)                               \n",
    "        X, S[k] = PUtx(samples,PowerTx, Pr, N)\n",
    "        PU=np.multiply(H.T,X)\n",
    "        Z = PU + n\n",
    "        \n",
    "        SNR[:,k] = np.mean(np.abs(PU)**2,axis=1)/PowerNo\n",
    "        Y[k,:] = np.sum(np.abs(Z)**2,axis=1)/(PowerNo*samples)\n",
    "\n",
    "    meanSNR = np.mean(SNR[:,S==1],1)\n",
    "    meanSNRdB = 10*np.log10(meanSNR)\n",
    "    return Y,S,meanSNRdB\n",
    "\n",
    "def PUtx(samples,PowerTx, Pr, N ):\n",
    "    S = 0\n",
    "    X = np.zeros(samples)\n",
    "    if (np.random.rand(1) <= Pr):\n",
    "        S=1\n",
    "        X=np.random.randn(samples) * np.sqrt(PowerTx)\n",
    "    X= np.vstack([X]*N)\n",
    "    return [X,S]\n",
    "\n",
    "def gaussianNoise(PowerNo,samples):\n",
    "    N = 3\n",
    "    n= np.random.randn(N,samples)  * np.sqrt(PowerNo)\n",
    "   \n",
    "    return n\n",
    "\n",
    "def channel(N,d,g,kind,variance,samples):\n",
    "    H=np.zeros(N)\n",
    "    if (kind=='ray'):\n",
    "        H=np.sqrt(-2 * variance * np.log(np.random.rand(N)))/np.sqrt(2)\n",
    "    # elif kind=='nakagami':\n",
    "    #     m=1.5\n",
    "    #     omega=1\n",
    "    #     H = np.sqrt(np.gamrnd(m,omega/m,[N,1]))*np.sqrt(variance)\n",
    "    # elif kind=='rician':\n",
    "    #     # for i in range(N)\n",
    "    #     #     ricChan= comm.RicianChannel(\"MaximumDopplerShift\",\n",
    "          #      0,\"NumSamples\",1,\"ChannelFiltering\",0)\n",
    "    #     #     H(i,:) = abs(ricChan())\n",
    "    #     # end\n",
    "    #     # H=H*sqrt(variance)\n",
    "    #     pass\n",
    "    else:\n",
    "        H = np.ones(N,1)\n",
    "    H = np.array(H*g)# Fading + path-loss (amplitude loss)\n",
    "    H = np.vstack([H]*samples)\n",
    "    return H\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,SNR_train=MCS(t,realiz=250)\n",
    "X_test,y_test,SNR_test=MCS(t,realiz=50000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 1.2633424201145262\n"
     ]
    }
   ],
   "source": [
    "import scipy.special\n",
    "# Calculate the threshold using incomplete gamma function\n",
    "threshold = 2*scipy.special.gammaincinv(samples/2, 1 - Pf) / samples\n",
    "\n",
    "print(\"Threshold:\", threshold)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  0.3]\n",
      "[[ 0.92847669 -0.70710678]\n",
      " [ 0.37139068  0.70710678]]\n",
      "Steady-state probability of Sunny: 0.714\n",
      "Steady-state probability of Rainy: 0.286\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the transition matrix\n",
    "transition_matrix = np.array([[0.8, 0.2], [0.5, 0.5]])\n",
    "\n",
    "# Solve for the stationary distribution\n",
    "eigenvalues, eigenvectors = np.linalg.eig(transition_matrix.T)\n",
    "stationary_distribution = np.real(eigenvectors[:, 0] / np.sum(eigenvectors[:, 0]))\n",
    "\n",
    "print(eigenvalues)\n",
    "print(eigenvectors)\n",
    "# Print the steady-state probabilities\n",
    "states = [\"Sunny\", \"Rainy\"]\n",
    "for state, probability in zip(states, stationary_distribution):\n",
    "    print(f\"Steady-state probability of {state}: {probability:.3f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cbook import to_filehandle\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from scipy import special\n",
    "import tensorflow as tf\n",
    "tf.autograph.set_verbosity(1)\n",
    "\n",
    "\n",
    "\n",
    "class Classification:\n",
    "    #print(np.concatenate((y_pred.reshpipape(len(y_pred),1), self.y_test.reshape(len(self.y_test),1)),1))\n",
    "    def __init__(self, X_train=None,y_train=None,X_test=None,y_test=None,Samples=50,SU=3,X_test_2=None,SNR=None):\n",
    "        self.X_train=X_train\n",
    "        self.y_train=y_train\n",
    "        self.X_test=X_test\n",
    "        self.y_test=y_test\n",
    "        self.Samples=Samples\n",
    "        self.SU=SU\n",
    "        self.X_test_2=X_test_2\n",
    "        self.SNR=SNR\n",
    "        # sc= StandardScaler()\n",
    "        # self.X_train = sc.fit_transform(self.X_train) \n",
    "        # self.X_test = sc.transform(self.X_test)\n",
    "        self.X_combined = np.r_[self.X_train, self.X_test]\n",
    "        self.y_combined = np.r_[self.y_train, self.y_test] \n",
    "        # self.y_train=self.y_train.reshape(-1)\n",
    "        # df_train.info()\n",
    "    def main(self):\n",
    "        val=[]\n",
    "    \n",
    "    def MLP(self):\n",
    "        type='MLP'\n",
    "        marker=\"$c$\"\n",
    "        ann = tf.keras.models.Sequential()\n",
    "\n",
    "        ann.add(tf.keras.layers.Dense(units=self.SU, activation='relu'))\n",
    "        ann.add(tf.keras.layers.Dense(units=len(self.y_train), activation='relu'))\n",
    "        ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "        ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "        ann.fit(self.X_train, self.y_train, epochs =500,verbose=0)\n",
    "        y_pred2=ann.predict(self.X_test)\n",
    "        y_pred2=y_pred2.flatten()\n",
    "        fpr, tpr, _ = metrics.roc_curve(self.y_test,  y_pred2)\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"darkgreen\",marker,int((len(fpr))*0.037)]\n",
    "    \n",
    "        # return output\n",
    "    \n",
    "        \n",
    "    \n",
    "    def Logistic(self):\n",
    "        classifier=LogisticRegression()\n",
    "        type='Logistic'\n",
    "        marker=\"o\"\n",
    "        parameters =[{'C': [0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4], 'max_iter':[1000],'solver': ['newton-cg','lbfgs','sag'], 'penalty': ['l2']},\n",
    "                     {'C': [0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4], 'max_iter':[1000], 'solver': ['saga','liblinear'], 'penalty': ['l1','l2']}]\n",
    "        grid_search = GridSearchCV(estimator = classifier,param_grid = parameters,scoring = 'accuracy',n_jobs = -1, cv=10,verbose=0)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_parameters=grid_search.best_params_\n",
    "        y_pred=grid_search.predict(self.X_test)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        accuracy=accuracy_score(self.y_test, y_pred)\n",
    "        cm2=confusion_matrix(self.y_train, grid_search.predict(self.X_train))\n",
    "        output=[type,accuracy*100,cm,cm2,best_accuracy*100,best_parameters]\n",
    "        y_pred2=grid_search.predict_proba(self.X_test)\n",
    "        y_pred2=y_pred2[:,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(self.y_test,  y_pred2)\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"gold\",marker,int((len(fpr))*0.037)]\n",
    "    \n",
    "        # ROC(self.X_test,self.y_test, y_pred2)\n",
    "        # ROC2(self.X_test,self.y_test, y_pred2)\n",
    "        \n",
    "        # return output\n",
    "            \n",
    "    def DecisionTree(self):\n",
    "        classifier= DecisionTreeClassifier()\n",
    "        type='DecisionTree'\n",
    "        marker=\"s\"\n",
    "        parameters =[{'max_depth':[2,3,4,5,6],'criterion': ['gini','entropy'],'min_samples_leaf':[1,2,3,4,5,6,7,8,9],'min_samples_leaf':[0.001,0.0025,0.005,0.075,0.01],'splitter':['best','random']}]\n",
    "        grid_search = GridSearchCV(estimator = classifier,param_grid=parameters,scoring = 'accuracy',n_jobs = -1, cv=10)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_parameters=grid_search.best_params_\n",
    "        y_pred=grid_search.predict(self.X_test)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        accuracy=accuracy_score(self.y_test, y_pred)\n",
    "        cm2=confusion_matrix(self.y_train, grid_search.predict(self.X_train))\n",
    "        output=[type,accuracy*100,cm,cm2,best_accuracy*100,best_parameters]\n",
    "    \n",
    "        y_pred2=grid_search.predict_proba(self.X_test)\n",
    "        y_pred2=y_pred2[:,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(self.y_test,  y_pred2)\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"gold\",marker,int((len(fpr))*0.037)]\n",
    "    \n",
    "        # ROC(self.X_test,self.y_test, y_pred2)\n",
    "        # ROC2(self.X_test,self.y_test, y_pred2)\n",
    "        \n",
    "        # return output\n",
    "    \n",
    "    def RandomForest(self):\n",
    "        classifier=RandomForestClassifier()\n",
    "        type='RandomForest'\n",
    "        marker=\"p\"\n",
    "        parameters =[{'n_estimators':[10,50,100,250,500] ,'criterion': ['gini','entropy'], 'max_features':['log2','sqrt']}]\n",
    "        grid_search = GridSearchCV(estimator = classifier,param_grid = parameters,scoring = 'accuracy',n_jobs = -1, cv=10)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_parameters=grid_search.best_params_\n",
    "        y_pred=grid_search.predict(self.X_test)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        accuracy=accuracy_score(self.y_test, y_pred)\n",
    "        cm2=confusion_matrix(self.y_train, grid_search.predict(self.X_train))\n",
    "        output=[type,accuracy*100,cm,cm2,best_accuracy*100,best_parameters]    \n",
    "        \n",
    "        y_pred2=grid_search.predict_proba(self.X_test)\n",
    "        y_pred2=y_pred2[:,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(self.y_test,  y_pred2)\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        if(len(fpr)>500):\n",
    "            val=(len(fpr))*0.037\n",
    "        elif (len(fpr)>10):\n",
    "            val=(len(fpr))*0.05\n",
    "        else:\n",
    "            val=1\n",
    "        return[fpr,tpr,auc,type,\"tan\",marker,val]\n",
    "    \n",
    "        # ROC(self.X_test,self.y_test, y_pred2)\n",
    "        # ROC2(self.X_test,self.y_test, y_pred2)\n",
    "        \n",
    "        # return output\n",
    "    \n",
    "    def KNN(self):\n",
    "        classifier = KNeighborsClassifier()\n",
    "        type='KNearestNeighbours'\n",
    "        marker=\"P\"\n",
    "        parameters =[{'n_neighbors': [5,7,9,11], 'weights':['uniform','distance'], 'n_jobs':[-1]}]\n",
    "        grid_search = GridSearchCV(estimator = classifier,param_grid = parameters,scoring = 'accuracy',n_jobs = -1, cv=10)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_parameters=grid_search.best_params_\n",
    "        y_pred=grid_search.predict(self.X_test)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        accuracy=accuracy_score(self.y_test, y_pred)\n",
    "        cm2=confusion_matrix(self.y_train, grid_search.predict(self.X_train))\n",
    "        plt=1\n",
    "        # plt=plot_learning_curve(estimator=classifier,title=type,X=self.X_combined, y=self.y_combined)\n",
    "        output=[type,accuracy*100,cm,cm2,best_accuracy*100,best_parameters,plt]\n",
    "        \n",
    "        y_pred2=grid_search.predict_proba(self.X_test)\n",
    "        y_pred2=y_pred2[:,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(self.y_test,  y_pred2)\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        if(len(fpr)>1000):\n",
    "            val=(len(fpr))*0.037\n",
    "        else:\n",
    "            val=1\n",
    "        return[fpr,tpr,auc,type,\"dimgrey\",marker,val]\n",
    "\n",
    "        # return output\n",
    "    \n",
    "    def NaiveBayes(self):\n",
    "        classifier = GaussianNB()\n",
    "        type='NaiveBayes'\n",
    "        marker=\"*\"\n",
    "        parameters =[{'var_smoothing':[1e-9]}]\n",
    "        grid_search = GridSearchCV(estimator = classifier,param_grid = parameters,scoring = 'accuracy',n_jobs = -1, cv=10)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_parameters=grid_search.best_params_\n",
    "        y_pred=grid_search.predict(self.X_test)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        accuracy=accuracy_score(self.y_test, y_pred)\n",
    "        cm2=confusion_matrix(self.y_train, grid_search.predict(self.X_train))\n",
    "        plt=1\n",
    "        # plt=plot_learning_curve(estimator=classifier,title=type,X=self.X_combined, y=self.y_combined)\n",
    "        output=[type,accuracy*100,cm,cm2,best_accuracy*100,best_parameters,plt]\n",
    "        \n",
    "        y_pred2=grid_search.predict_proba(self.X_test)\n",
    "        y_pred2=y_pred2[:,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(self.y_test,  y_pred2)\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"purple\",marker,int((len(fpr))*0.037)]\n",
    "    \n",
    "        # return output\n",
    "        \n",
    "    def LinearSVM(self):      \n",
    "        classifier=SVC()\n",
    "        type='LinearSVM'\n",
    "        marker=\"X\"\n",
    "        parameters =[{'C': [0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4], 'kernel': ['linear'], 'probability':[True]}]\n",
    "        grid_search = GridSearchCV(estimator = classifier,param_grid = parameters,scoring = 'accuracy',n_jobs = -1, cv=10)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_parameters=grid_search.best_params_\n",
    "        y_pred=grid_search.predict(self.X_test)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        accuracy=accuracy_score(self.y_test, y_pred)\n",
    "        cm2=confusion_matrix(self.y_train, grid_search.predict(self.X_train))\n",
    "        plt=1\n",
    "        # plt=plot_learning_curve(estimator=classifier,title=type,X=self.X_combined, y=self.y_combined)\n",
    "        output=[type,accuracy*100,cm,cm2,best_accuracy*100,best_parameters,plt]\n",
    "        \n",
    "        y_pred2=grid_search.predict_proba(self.X_test)\n",
    "        y_pred2=y_pred2[:,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(self.y_test,  y_pred2)\n",
    "        meanLSVM_Pd = np.mean(tpr)\n",
    "        maenLSVM_Pfa = np.mean(fpr)\n",
    "        print(fpr)\n",
    "        print(tpr)\n",
    "        return[fpr,tpr,auc,type,\"fuchsia\",marker,int((len(fpr))*0.037)]\n",
    "    \n",
    "        # return output\n",
    "        \n",
    "    def GaussianSVM(self):      \n",
    "        classifier=SVC()\n",
    "        type='GaussianSVM'\n",
    "        marker=2\n",
    "        parameters =[{'C': [0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 'scale'], 'probability':[True]}]\n",
    "        grid_search = GridSearchCV(estimator = classifier,param_grid = parameters,scoring = 'accuracy',n_jobs = -1, cv=10)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_parameters=grid_search.best_params_\n",
    "        y_pred=grid_search.predict(self.X_test)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        accuracy=accuracy_score(self.y_test, y_pred)\n",
    "        cm2=confusion_matrix(self.y_train, grid_search.predict(self.X_train))\n",
    "        plt=1\n",
    "        # plt=plot_learning_curve(estimator=classifier,title=type,X=self.X_combined, y=self.y_combined)\n",
    "        output=[type,accuracy*100,cm,cm2,best_accuracy*100,best_parameters,plt]\n",
    "        \n",
    "        y_pred2=grid_search.predict_proba(self.X_test)\n",
    "        y_pred2=y_pred2[:,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(self.y_test,  y_pred2)\n",
    "        meanGSVM_Pd = np.mean(tpr)\n",
    "        maenGSVM_Pfa = np.mean(fpr)\n",
    "        with open('GSVM.csv','a') as f:\n",
    "            np.savetxt(f, np.array([meanGSVM_Pd, maenGSVM_Pfa]).reshape(1,-1), delimiter=',')\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"black\",marker,int((len(fpr))*0.037)]\n",
    "    \n",
    "        # return output\n",
    "    \n",
    "        \n",
    "    def XGBoost(self):\n",
    "        classifier=XGBClassifier()\n",
    "        type='XGBoost'\n",
    "        marker=\"D\"\n",
    "        parameters =[{'n_jobs':[-1],'use_label_encoder':[False],'eval_metric':['error','logloss', 'auc'], 'objective':['binary:logistic'],\n",
    "        'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1], 'max_depth': [1, 3, 5, 7, 9]}]\n",
    "        grid_search = GridSearchCV(estimator = classifier,param_grid = parameters,scoring = 'accuracy',n_jobs = -1, cv=10, verbose=0)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_parameters=grid_search.best_params_\n",
    "        y_pred=grid_search.predict(self.X_test)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        accuracy=accuracy_score(self.y_test, y_pred)\n",
    "        cm2=confusion_matrix(self.y_train, grid_search.predict(self.X_train))\n",
    "        plt=1\n",
    "        # plt=plot_learning_curve(estimator=classifier,title=type,X=self.X_combined, y=self.y_combined)\n",
    "        output=[type,accuracy*100,cm,cm2,best_accuracy*100,best_parameters,plt]\n",
    "        \n",
    "        y_pred2=grid_search.predict_proba(self.X_test)\n",
    "        y_pred2=y_pred2[:,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(self.y_test,  y_pred2)\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"pink\",marker,int((len(fpr))*0.037)]\n",
    "    \n",
    "        # return output\n",
    "    \n",
    "\n",
    "    def CatBoost(self):\n",
    "        classifier=CatBoostClassifier()\n",
    "        type='CatBoost'\n",
    "        marker=\"d\"\n",
    "        parameters =[{'custom_loss':['AUC', 'Accuracy'], 'verbose':[False], 'allow_writing_files':[False] }]\n",
    "        grid_search = GridSearchCV(estimator = classifier,param_grid = parameters,scoring = 'accuracy',n_jobs = -1, cv=10)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_parameters=grid_search.best_params_\n",
    "        y_pred=grid_search.predict(self.X_test)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        accuracy=accuracy_score(self.y_test, y_pred)\n",
    "        cm2=confusion_matrix(self.y_train, grid_search.predict(self.X_train))\n",
    "        plt=1\n",
    "        # plt=plot_learning_curve(estimator=classifier,title=type,X=self.X_combined, y=self.y_combined)\n",
    "        output=[type,accuracy*100,cm,cm2,best_accuracy*100,best_parameters,plt]\n",
    "        \n",
    "        y_pred2=grid_search.predict_proba(self.X_test)\n",
    "        y_pred2=y_pred2[:,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(self.y_test,  y_pred2)\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"lightgrey\",marker,int((len(fpr))*0.037)]\n",
    "    \n",
    "        # return output\n",
    "    \n",
    "        \n",
    "    def ADABoost(self):\n",
    "        classifier=AdaBoostClassifier()\n",
    "        type='ADABoost'\n",
    "        marker=\"|\"\n",
    "        parameters =[{'n_estimators':[75], 'algorithm':['SAMME', 'SAMME.R']}]\n",
    "        grid_search = GridSearchCV(estimator = classifier,param_grid = parameters,scoring = 'accuracy',n_jobs = -1, cv=10)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_parameters=grid_search.best_params_\n",
    "        y_pred=grid_search.predict(self.X_test)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        accuracy=accuracy_score(self.y_test, y_pred)\n",
    "        cm2=confusion_matrix(self.y_train, grid_search.predict(self.X_train))\n",
    "        plt=1\n",
    "        # plt=plot_learning_curve(estimator=classifier,title=type,X=self.X_combined, y=self.y_combined)\n",
    "        output=[type,accuracy*100,cm,cm2,best_accuracy*100,best_parameters,plt]\n",
    "        \n",
    "        y_pred2=grid_search.predict_proba(self.X_test)\n",
    "        y_pred2=y_pred2[:,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(self.y_test,  y_pred2)\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"olive\",marker,int((len(fpr))*0.037)]\n",
    "    \n",
    "        # return output\n",
    "        \n",
    "    def OR(self):\n",
    "        Pfa_target=[x/10000.0 for x in range(25,10000,25)]\n",
    "        tpr=[]\n",
    "        fpr=[]\n",
    "        type=\"OR\"\n",
    "        marker=\"v\"\n",
    "        for i in range(len(Pfa_target)):\n",
    "            alpha=1-Pfa_target[i]\n",
    "            lambd = 2*special.gammainccinv(self.Samples/2,Pfa_target[i])/self.Samples\n",
    "            # lambd = 2*special.gammainccinv(self.SU/2,Pfa_target[i])/self.SU\n",
    "            y_pred=np.array(np.sum(self.X_test>=lambd,1)>0, dtype=int)    \n",
    "\n",
    "            tn=np.sum(np.logical_not(self.y_test)&np.logical_not(y_pred))\n",
    "            tp=np.sum(np.logical_and(self.y_test, y_pred))\n",
    "            fn=np.sum(np.logical_and(self.y_test,np.logical_not(y_pred)))\n",
    "            fp=np.sum(np.logical_and(np.logical_not(self.y_test),y_pred))\n",
    "            tpr.append(tp/(tp+fn))\n",
    "            fpr.append(fp/(fp+tn))\n",
    "        \n",
    "        meanOR_Pd = np.mean(tpr)\n",
    "        maenOR_Pfa = np.mean(fpr)\n",
    "        with open('OR.csv','a') as f:\n",
    "            np.savetxt(f, np.array([meanOR_Pd, maenOR_Pfa]).reshape(1,-1), delimiter=',')\n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"darkred\",marker,int((len(fpr))*0.01)]\n",
    "    \n",
    "    def AND(self):\n",
    "        Pfa_target=[x/10000.0 for x in range(25,10000,25)]\n",
    "        tpr=[]\n",
    "        fpr=[]\n",
    "        type=\"AND\"\n",
    "        marker=\">\"\n",
    "        for i in range(len(Pfa_target)):\n",
    "            alpha=1-Pfa_target[i]\n",
    "            lambd = 2*special.gammainccinv(self.Samples/2,Pfa_target[i])/self.Samples\n",
    "            # lambd = 2*special.gammainccinv(self.SU/2,Pfa_target[i])/self.SU\n",
    "            y_pred=np.array(np.sum(self.X_test>=lambd,1)==self.SU, dtype=int)\n",
    "            \n",
    "            tn=np.sum(np.logical_not(self.y_test)&np.logical_not(y_pred))\n",
    "            tp=np.sum(np.logical_and(self.y_test, y_pred))\n",
    "            fn=np.sum(np.logical_and(self.y_test,np.logical_not(y_pred)))\n",
    "            fp=np.sum(np.logical_and(np.logical_not(self.y_test),y_pred))\n",
    "            tpr.append(tp/(tp+fn))\n",
    "            fpr.append(fp/(fp+tn))\n",
    "        \n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"brown\",marker,int((len(fpr))*0.01)]\n",
    "    \n",
    "    def MRC(self):\n",
    "        Pfa_target=[x/10000.0 for x in range(25,10000,25)]\n",
    "        tpr=[]\n",
    "        fpr=[]\n",
    "        type=\"MRC\"\n",
    "        marker=\"<\"\n",
    "        for i in range(len(Pfa_target)):\n",
    "            alpha=1-Pfa_target[i]\n",
    "            lambd = 2*special.gammainccinv(self.Samples/2,Pfa_target[i])/self.Samples\n",
    "            # lambd = 2*special.gammainccinv(self.SU/2,Pfa_target[i])/self.SU\n",
    "            y_pred=np.array(np.sum(self.X_test_2,1)>lambd, dtype=int)\n",
    "            \n",
    "            tn=np.sum(np.logical_not(self.y_test)&np.logical_not(y_pred))\n",
    "            tp=np.sum(np.logical_and(self.y_test, y_pred))\n",
    "            fn=np.sum(np.logical_and(self.y_test,np.logical_not(y_pred)))\n",
    "            fp=np.sum(np.logical_and(np.logical_not(self.y_test),y_pred))\n",
    "            tpr.append(tp/(tp+fn))\n",
    "            fpr.append(fp/(fp+tn))\n",
    "        \n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"lightcoral\",marker,int((len(fpr))*0.01)]\n",
    "        \n",
    "    def S1(self):\n",
    "        Pfa_target=[x/10000.0 for x in range(25,10000,25)]\n",
    "        tpr=[]\n",
    "        fpr=[]\n",
    "        type=\"S1\"\n",
    "        marker=\"1\"\n",
    "        for i in range(len(Pfa_target)):\n",
    "            alpha=1-Pfa_target[i]\n",
    "            lambd = 2*special.gammainccinv(self.Samples/2,Pfa_target[i])/self.Samples\n",
    "            # lambd = 2*special.gammainccinv(self.SU/2,Pfa_target[i])/self.SU\n",
    "            y_pred=np.array(self.X_test[:,0]>=lambd, dtype=int)\n",
    "            \n",
    "            tn=np.sum(np.logical_not(self.y_test)&np.logical_not(y_pred))\n",
    "            tp=np.sum(np.logical_and(self.y_test, y_pred))\n",
    "            fn=np.sum(np.logical_and(self.y_test,np.logical_not(y_pred)))\n",
    "            fp=np.sum(np.logical_and(np.logical_not(self.y_test),y_pred))\n",
    "            tpr.append(tp/(tp+fn))\n",
    "            fpr.append(fp/(fp+tn))\n",
    "        \n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"midnightblue\",marker,int((len(fpr))*0.01)]\n",
    "        \n",
    "    def S2(self):\n",
    "        Pfa_target=[x/10000.0 for x in range(25,10000,25)]\n",
    "        tpr=[]\n",
    "        fpr=[]\n",
    "        type=\"S2\"\n",
    "        marker=\"2\"\n",
    "        for i in range(len(Pfa_target)):\n",
    "            alpha=1-Pfa_target[i]\n",
    "            lambd = 2*special.gammainccinv(self.Samples/2,Pfa_target[i])/self.Samples\n",
    "            # lambd = 2*special.gammainccinv(self.SU/2,Pfa_target[i])/self.SU\n",
    "            y_pred=np.array(self.X_test[:,1]>=lambd, dtype=int)\n",
    "            \n",
    "            tn=np.sum(np.logical_not(self.y_test)&np.logical_not(y_pred))\n",
    "            tp=np.sum(np.logical_and(self.y_test, y_pred))\n",
    "            fn=np.sum(np.logical_and(self.y_test,np.logical_not(y_pred)))\n",
    "            fp=np.sum(np.logical_and(np.logical_not(self.y_test),y_pred))\n",
    "            tpr.append(tp/(tp+fn))\n",
    "            fpr.append(fp/(fp+tn))\n",
    "        \n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"royalblue\",marker,int((len(fpr))*0.01)]\n",
    "    \n",
    "    def S3(self):\n",
    "        Pfa_target=[x/10000.0 for x in range(25,10000,25)]\n",
    "        tpr=[]\n",
    "        fpr=[]\n",
    "        type=\"S3\"\n",
    "        marker=\"3\"\n",
    "        for i in range(len(Pfa_target)):\n",
    "            alpha=1-Pfa_target[i]\n",
    "            lambd = 2*special.gammainccinv(self.Samples/2,Pfa_target[i])/self.Samples\n",
    "            # lambd = 2*special.gammainccinv(self.SU/2,Pfa_target[i])/self.SU\n",
    "            y_pred=np.array(self.X_test[:,2]>=lambd, dtype=int)\n",
    "            \n",
    "            tn=np.sum(np.logical_not(self.y_test)&np.logical_not(y_pred))\n",
    "            tp=np.sum(np.logical_and(self.y_test, y_pred))\n",
    "            fn=np.sum(np.logical_and(self.y_test,np.logical_not(y_pred)))\n",
    "            fp=np.sum(np.logical_and(np.logical_not(self.y_test),y_pred))\n",
    "            tpr.append(tp/(tp+fn))\n",
    "            fpr.append(fp/(fp+tn))\n",
    "        \n",
    "        auc = metrics.auc(fpr,tpr)\n",
    "        return[fpr,tpr,auc,type,\"lightsteelblue\",marker,int((len(fpr))*0.01)]\n",
    "        \n",
    "        \n",
    "      \n",
    "def plot_learning_curve(estimator,title,X,y,cv=10,n_jobs=-1,train_sizes=np.linspace(0.1, 1.0, 10)):\n",
    "    y=y.reshape(-1)\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 10))\n",
    "    axes[0].set_title(title)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(estimator,X,y,cv=cv,n_jobs=n_jobs,train_sizes=train_sizes,return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes,train_scores_mean - train_scores_std,train_scores_mean + train_scores_std,alpha=0.1,color=\"r\")\n",
    "    axes[0].fill_between(train_sizes,test_scores_mean - test_scores_std,test_scores_mean + test_scores_std,alpha=0.1,color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, \"o-\")\n",
    "    axes[1].fill_between(train_sizes,fit_times_mean - fit_times_std,fit_times_mean + fit_times_std,alpha=0.1,)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    fit_time_argsort = fit_times_mean.argsort()\n",
    "    fit_time_sorted = fit_times_mean[fit_time_argsort]\n",
    "    test_scores_mean_sorted = test_scores_mean[fit_time_argsort]\n",
    "    test_scores_std_sorted = test_scores_std[fit_time_argsort]\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_time_sorted, test_scores_mean_sorted, \"o-\")\n",
    "    axes[2].fill_between(fit_time_sorted,test_scores_mean_sorted - test_scores_std_sorted,test_scores_mean_sorted + test_scores_std_sorted,alpha=0.1,)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "    plt.subplots_adjust(left=0.1,bottom=0.1,right=0.9,top=0.9,wspace=0.4,hspace=0.4)\n",
    "    plt.show()\n",
    "    return plt\n",
    "    # cv = ShuffleSplit(n_splits=50, test_size=0.2)\n",
    "    \n",
    "def ROC2(X_test,y_test, y_pred2):\n",
    "    y_pred2=y_pred2[:,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred2)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "    \n",
    "    pd1=[]\n",
    "    pd2=[]\n",
    "    pd3=[]\n",
    "    \n",
    "    Pfa_target=[x/10000.0 for x in range(25,10000,25)]\n",
    "    tpr_s1=[]\n",
    "    fpr_s1=[]\n",
    "    tpr_s2=[]\n",
    "    fpr_s2=[]\n",
    "    tpr_s3=[]\n",
    "    fpr_s3=[]\n",
    "    for i in range(len(Pfa_target)):\n",
    "        alpha=1-Pfa_target[i]\n",
    "        lambd = 2*special.gammainccinv(25,Pfa_target[i])/50\n",
    "        # lambd = 2*special.gammainccinv(3/2,Pfa_target[i])/3\n",
    "        \n",
    "        pd1.append(special.gammainc(lambd*50/(2*1.276386), 25))\n",
    "        pd2.append(special.gammainc(lambd*50/(2*1.249404), 25))\n",
    "        pd3.append(special.gammainc(lambd*50/(2*1.079713), 25))\n",
    "        \n",
    "        #S1\n",
    "        y_pred_s1=np.array(X_test[:,0]>=lambd, dtype=int)\n",
    "        tn_s1=0\n",
    "        tp_s1=0\n",
    "        fn_s1=0\n",
    "        fp_s1=0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i]==0 and y_pred_s1[i]==0:\n",
    "                tn_s1+=1\n",
    "            elif y_test[i]==1 and y_pred_s1[i]==1:\n",
    "                tp_s1+=1\n",
    "            elif y_test[i]==1 and y_pred_s1[i]==0:\n",
    "                fn_s1+=1\n",
    "            else:\n",
    "                fp_s1+=1\n",
    "        tpr_s1.append(tp_s1/(tp_s1+fn_s1))\n",
    "        fpr_s1.append(fp_s1/(fp_s1+tn_s1))\n",
    "        \n",
    "        #S2\n",
    "        y_pred_s2=np.array(X_test[:,1]>=lambd, dtype=int)\n",
    "        tn_s2=0\n",
    "        tp_s2=0\n",
    "        fn_s2=0\n",
    "        fp_s2=0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i]==0 and y_pred_s2[i]==0:\n",
    "                tn_s2+=1\n",
    "            elif y_test[i]==1 and y_pred_s2[i]==1:\n",
    "                tp_s2+=1\n",
    "            elif y_test[i]==1 and y_pred_s2[i]==0:\n",
    "                fn_s2+=1\n",
    "            else:\n",
    "                fp_s2+=1\n",
    "        tpr_s2.append(tp_s2/(tp_s2+fn_s2))\n",
    "        fpr_s2.append(fp_s2/(fp_s2+tn_s2))\n",
    "        \n",
    "        #S3\n",
    "        y_pred_s3=np.array(X_test[:,2]>=lambd, dtype=int)\n",
    "        tn_s3=0\n",
    "        tp_s3=0\n",
    "        fn_s3=0\n",
    "        fp_s3=0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i]==0 and y_pred_s3[i]==0:\n",
    "                tn_s3+=1\n",
    "            elif y_test[i]==1 and y_pred_s3[i]==1:\n",
    "                tp_s3+=1\n",
    "            elif y_test[i]==1 and y_pred_s3[i]==0:\n",
    "                fn_s3+=1\n",
    "            else:\n",
    "                fp_s3+=1\n",
    "        tpr_s3.append(tp_s3/(tp_s3+fn_s3))\n",
    "        fpr_s3.append(fp_s3/(fp_s3+tn_s3))\n",
    "        \n",
    "    \n",
    "    \n",
    "    PFA=[]\n",
    "    PFA.append(Pfa_target)\n",
    "    PFA=np.transpose(PFA)\n",
    "    plt.title('ROC Curve')\n",
    "    plt.grid()\n",
    "    plt.plot(PFA, pd1, 'r',       label=\"Theoretical PD1: %0.4f\"%metrics.auc(PFA,pd1))\n",
    "    plt.plot(fpr_s1, tpr_s1, 'r--', label=\"Practical PD1: %0.4f\"%metrics.auc(fpr_s1,tpr_s1))\n",
    "    plt.plot(PFA, pd2, 'g',       label=\"Theoretical PD2: %0.4f\"%metrics.auc(PFA,pd2))\n",
    "    plt.plot(fpr_s2, tpr_s2, 'g--', label=\"Practical PD2: %0.4f\"%metrics.auc(fpr_s2,tpr_s2))\n",
    "    plt.plot(PFA, pd3, 'b',       label=\"Theoretical PD3: %0.4f\"%metrics.auc(PFA,pd3))\n",
    "    plt.plot(fpr_s3, tpr_s3, 'b--', label=\"Practical PD3: %0.4f\"%metrics.auc(fpr_s3,tpr_s3))\n",
    "    plt.plot(fpr, tpr, 'y', label = 'NB= %0.4f' %auc)\n",
    "    \n",
    "    plt.legend(loc = 'lower right')\n",
    "    # plt.xlim([0, 0.4])\n",
    "    # plt.ylim([0.6, 1])\n",
    "    # plt.xticks([x/100 for x in range(0,45,5)])\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('Probability of Detection')\n",
    "    plt.xlabel('Pobability of False Alarm')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo=Classification(X_train=X_train,y_train=y_train,X_test=X_test,\n",
    "                    y_test=y_test,Samples=samples,SU=N,SNR=SNR_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=[]\n",
    "file.append(demo.LinearSVM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
